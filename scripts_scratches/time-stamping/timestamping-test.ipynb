{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f83fcd",
   "metadata": {},
   "source": [
    "# Function that generates the timestamp range of when something important happens\n",
    "\n",
    "#### i.e. when the shrimp are \"close\" to each other\n",
    "#### The function takes in a dataframe that is outputted throug tracktor, and identifies when the two objectd are close to each other within a certain threshhold of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852da5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load necessary packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracktor as tr\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e5a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, read in the \"timestamped\" CSV file from whatever directory \n",
    "\n",
    "df = pd.read_csv('/Users/lukefields/Downloads/BlackWhiteResult2full_tracked2.csv')\n",
    "df = df.drop([\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275b991",
   "metadata": {},
   "source": [
    "#### We are going to try out the ranges now, by having a sort of recursive function that looks to see if the previous distance has exited the \"important\" range we have established"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29634f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Previous\"] = (df[\"Distance\"].shift(1)).fillna(df['Distance'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592cf29",
   "metadata": {},
   "source": [
    "#### Now, we need to establish an \"Enter\" and \"Exit\" type of range generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b86b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ashley_df[\"Enter\"] = ashley_df.eval(\"Distance <= 130 and not (Previous <= 130)\").cumsum()\n",
    "ashley_df[\"Exit\"] = ashley_df.eval(\"Previous <= 130 and not (Distance <= 130)\")\\\n",
    ".shift(-1).fillna(True).cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486920e3",
   "metadata": {},
   "source": [
    "#### Generate when it starts and ends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0045b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ashley_df.merge(ashley_df.drop_duplicates(\"Exit\", keep = \"first\")[[\"Frame\", \"Exit\"]],\n",
    "                      left_on = \"Enter\", right_on = \"Exit\", how = \"left\", suffixes = [\"\", \"_end\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c2bf6",
   "metadata": {},
   "source": [
    "#### Dropping the duplicates identifies the unique different interval series, and BOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49cdc9b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Frame_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>90.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>105.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>108.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame  Frame_end\n",
       "0      3.0        3.0\n",
       "51    54.0       52.0\n",
       "53    56.0       54.0\n",
       "65    68.0       60.0\n",
       "69    72.0       68.0\n",
       "87    90.0       73.0\n",
       "102  105.0       90.0\n",
       "105  108.0      106.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp.drop_duplicates(subset = \"Enter\", keep = \"first\")[[\"Frame\", \"Frame_end\"]]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad70cf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Frame_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Frame  Frame_end\n",
       "0     3.0        3.0\n",
       "1     4.0        5.0\n",
       "6     9.0        9.0\n",
       "12   15.0       16.0\n",
       "31   34.0       36.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashley_df = pd.read_csv('/Users/lukefields/Desktop/Shrimp-Capstone/shrimp_data_out/ashley_test_timestamped.csv')\n",
    "ashley_df = ashley_df.drop([\"Unnamed: 0\"], axis = 1)\n",
    "let_say = 125\n",
    "\n",
    "ashley_df[\"Previous\"] = ashley_df[\"Distance\"].shift(1)\n",
    "ashley_df\n",
    "\n",
    "enter_eval = \"Distance <= \" + str(let_say) + \" and not (Previous <= \" + str(let_say) + \")\"\n",
    "exit_eval = \"Previous <= \" + str(let_say) + \" and not (Distance <= \" + str(let_say) + \")\"\n",
    "ashley_df[\"Enter\"] = ashley_df.eval(enter_eval).cumsum()\n",
    "ashley_df[\"Exit\"] = ashley_df.eval(exit_eval).shift(-1).fillna(True).cumsum()\n",
    "\n",
    "temp = ashley_df.merge(ashley_df.drop_duplicates(\"Exit\", keep = \"first\")[[\"Frame\", \"Exit\"]],\n",
    "                      left_on = \"Enter\", right_on = \"Exit\", how = \"left\", suffixes = [\"\", \"_end\"])\n",
    "\n",
    "temp = temp.drop_duplicates(subset = \"Enter\", keep = \"first\")[[\"Frame\", \"Frame_end\"]]\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f673f4d",
   "metadata": {},
   "source": [
    "# Ok, so how do we automate this process into one function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5aa91a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Previous</th>\n",
       "      <th>Enter</th>\n",
       "      <th>Exit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>126.321020</td>\n",
       "      <td>126.321020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>122.200655</td>\n",
       "      <td>126.321020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>124.145076</td>\n",
       "      <td>122.200655</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>127.192767</td>\n",
       "      <td>124.145076</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>127.251719</td>\n",
       "      <td>127.192767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>167.0</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>135.369864</td>\n",
       "      <td>133.304163</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>168.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>138.293167</td>\n",
       "      <td>135.369864</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>169.0</td>\n",
       "      <td>2.816667</td>\n",
       "      <td>144.886162</td>\n",
       "      <td>138.293167</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>170.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>146.874096</td>\n",
       "      <td>144.886162</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>171.0</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>146.986394</td>\n",
       "      <td>146.874096</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame  Timestamp    Distance    Previous  Enter  Exit\n",
       "0      3.0   0.050000  126.321020  126.321020      0     0\n",
       "1      4.0   0.066667  122.200655  126.321020      1     0\n",
       "2      5.0   0.083333  124.145076  122.200655      1     1\n",
       "3      6.0   0.100000  127.192767  124.145076      1     1\n",
       "4      7.0   0.116667  127.251719  127.192767      1     1\n",
       "..     ...        ...         ...         ...    ...   ...\n",
       "164  167.0   2.783333  135.369864  133.304163      4     4\n",
       "165  168.0   2.800000  138.293167  135.369864      4     4\n",
       "166  169.0   2.816667  144.886162  138.293167      4     4\n",
       "167  170.0   2.833333  146.874096  144.886162      4     4\n",
       "168  171.0   2.850000  146.986394  146.874096      4     5\n",
       "\n",
       "[169 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashley_df[\"Previous\"] = (ashley_df[\"Distance\"].shift(1)).fillna(ashley_df['Distance'])\n",
    "ashley_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edc4766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame With NaN values : \n",
      "\n",
      "   Name Articles Improved\n",
      "a  NaN      NaN      NaN\n",
      "b  NaN      NaN      NaN\n",
      "c  NaN      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Name', 'Articles', 'Improved'],\n",
    "        index = ['a', 'b', 'c'])\n",
    "  \n",
    "print(\"Empty DataFrame With NaN values : \\n\\n\", df)\n",
    "  \n",
    "# adding rows to an empty\n",
    "# dataframe at existing index\n",
    "df.loc['a'] = ['Ankita', 50, 100]\n",
    "df.loc['b'] = ['Ankit', 60, 120]\n",
    "df.loc['c'] = ['Harsh', 30, 60]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c240e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_frame(df, dist_cutoff):\n",
    "    if ((df.loc[df[\"Distance\"] < dist_cutoff]).empty == True):\n",
    "        df_temp = pd.DataFrame(columns = [\"Pair\", \"Frame\", \"Frame_end\"],\n",
    "                              index = [0])\n",
    "        df_pair = df[\"Pair\"][0]\n",
    "        df_temp.loc[0] = [df_pair, 0, 0]\n",
    "        return df_temp\n",
    "    else:\n",
    "        df[\"Previous\"] = (df[\"Distance\"].shift(1)).fillna(ashley_df['Distance'])\n",
    "\n",
    "        enter_eval = \"Distance <= \" + str(dist_cutoff) + \" and not (Previous <= \" + str(dist_cutoff) + \")\"\n",
    "        exit_eval = \"Previous <= \" + str(dist_cutoff) + \" and not (Distance <= \" + str(dist_cutoff) + \")\"\n",
    "        df[\"Enter\"] = df.eval(enter_eval).cumsum()\n",
    "        df[\"Exit\"] = df.eval(exit_eval).shift(-1).fillna(True).cumsum()\n",
    "\n",
    "        df_temp = df.merge(df.drop_duplicates(\"Exit\", keep = \"first\")[[\"Frame\", \"Exit\"]],\n",
    "                              left_on = \"Enter\", right_on = \"Exit\", how = \"left\", suffixes = [\"\", \"_end\"])\n",
    "\n",
    "        df_temp = df_temp.drop_duplicates(subset = \"Enter\", keep = \"first\")[[\"Frame\", \"Frame_end\"]]\n",
    "        return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19eb6568",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Pair'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Pair'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimportant_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mashley_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m, in \u001b[0;36mimportant_frame\u001b[0;34m(df, dist_cutoff)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m dist_cutoff])\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     df_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPair\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame_end\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m                           index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m     df_pair \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPair\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m     df_temp\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m [df_pair, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_temp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Pair'"
     ]
    }
   ],
   "source": [
    "important_frame(ashley_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c13819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_frames(df, dist_cutoff):\n",
    "    df[\"Previous\"] = (df[\"Distance\"].shift(1)).fillna(ashley_df['Distance'])\n",
    "\n",
    "    enter_eval = \"Distance <= \" + str(dist_cutoff) + \" and not (Previous <= \" + str(dist_cutoff) + \")\"\n",
    "    exit_eval = \"Previous <= \" + str(dist_cutoff) + \" and not (Distance <= \" + str(dist_cutoff) + \")\"\n",
    "    df[\"Enter\"] = df.eval(enter_eval).cumsum()\n",
    "    df[\"Exit\"] = df.eval(exit_eval).shift(-1).fillna(True).cumsum()\n",
    "\n",
    "    df_temp = df.merge(df.drop_duplicates(\"Exit\", keep = \"first\")[[\"Frame\", \"Exit\"]],\n",
    "                          left_on = \"Enter\", right_on = \"Exit\", how = \"left\", suffixes = [\"\", \"_end\"])\n",
    "\n",
    "    df_temp = df_temp.drop_duplicates(subset = \"Enter\", keep = \"first\")[[\"Frame\", \"Frame_end\"]]\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0105834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Frame_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Frame  Frame_end\n",
       "0     3.0        3.0\n",
       "1     4.0        4.0\n",
       "6     9.0        9.0\n",
       "31   34.0       35.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_frames(ashley_df, 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f044acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# The function below takes in every individual distance dataframe generated \n",
    "# And then concatentes them into one\n",
    "\n",
    "\n",
    "# Only parameter is the filepath where each individual pair csv file is stores (Shrimp A and B)\n",
    "def combine_dfs(filepath):\n",
    "    all_files = glob.glob(os.path.join(filepath, \"*.csv\"))\n",
    "\n",
    "    df_storage = []\n",
    "    for filepath in all_files:\n",
    "        individual_df = pd.read_csv(filepath, index_col = None, header = 0)\n",
    "        df_storage.append(individual_df)\n",
    "\n",
    "    combined_df = pd.concat(df_storage, axis = 0, ignore_index = True)\n",
    "    combined_df = combined_df.drop([\"Unnamed: 0\"], axis = 1).sort_values(\"Pair\", ascending = True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "test_path = \"/Users/lukefields/Desktop/Shrimp-Capstone/test_data_out/\"\n",
    "zebra_comb = combine_dfs(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d63d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149979</th>\n",
       "      <td>('A', 'B')</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0:04:10: 0</td>\n",
       "      <td>50.675908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139987</th>\n",
       "      <td>('A', 'B')</td>\n",
       "      <td>5008.0</td>\n",
       "      <td>0:01:23:46</td>\n",
       "      <td>96.587055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139986</th>\n",
       "      <td>('A', 'B')</td>\n",
       "      <td>5007.0</td>\n",
       "      <td>0:01:23:45</td>\n",
       "      <td>96.969558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139985</th>\n",
       "      <td>('A', 'B')</td>\n",
       "      <td>5006.0</td>\n",
       "      <td>0:01:23:43</td>\n",
       "      <td>98.314128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139984</th>\n",
       "      <td>('A', 'B')</td>\n",
       "      <td>5005.0</td>\n",
       "      <td>0:01:23:41</td>\n",
       "      <td>100.498698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84983</th>\n",
       "      <td>('D', 'E')</td>\n",
       "      <td>9996.0</td>\n",
       "      <td>0:02:46:59</td>\n",
       "      <td>226.578061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84982</th>\n",
       "      <td>('D', 'E')</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>0:02:46:58</td>\n",
       "      <td>225.084797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84981</th>\n",
       "      <td>('D', 'E')</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>0:02:46:56</td>\n",
       "      <td>222.018402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84993</th>\n",
       "      <td>('D', 'E')</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>0:02:46:76</td>\n",
       "      <td>249.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74991</th>\n",
       "      <td>('D', 'E')</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0:00:00: 6</td>\n",
       "      <td>52.463354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Pair    Frame   Timestamp    Distance\n",
       "149979  ('A', 'B')  15000.0  0:04:10: 0   50.675908\n",
       "139987  ('A', 'B')   5008.0  0:01:23:46   96.587055\n",
       "139986  ('A', 'B')   5007.0  0:01:23:45   96.969558\n",
       "139985  ('A', 'B')   5006.0  0:01:23:43   98.314128\n",
       "139984  ('A', 'B')   5005.0  0:01:23:41  100.498698\n",
       "...            ...      ...         ...         ...\n",
       "84983   ('D', 'E')   9996.0  0:02:46:59  226.578061\n",
       "84982   ('D', 'E')   9995.0  0:02:46:58  225.084797\n",
       "84981   ('D', 'E')   9994.0  0:02:46:56  222.018402\n",
       "84993   ('D', 'E')  10006.0  0:02:46:76  249.971253\n",
       "74991   ('D', 'E')      4.0  0:00:00: 6   52.463354\n",
       "\n",
       "[149980 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zebra_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa2c5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "shrimp_df_0308 = pd.read_csv('/Users/lukefields/Desktop/Shrimp-Capstone/test_0308/AB_0308_distances.csv')\n",
    "shrimp_df_0308 = shrimp_df_0308.drop([\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1edfd4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('C', 'E')\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zebra_comb[\"Pair\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32d7cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_timestamps(df, dist_cutoff):\n",
    "    if ((df.loc[df[\"Distance\"] < dist_cutoff]).empty == True):\n",
    "        df_temp = pd.DataFrame(columns = [\"Pair\", \"Timestamp\", \"Timestamp_end\"],\n",
    "                              index = [0])\n",
    "        df_pair = df[\"Pair\"][0]\n",
    "        df_temp.loc[0] = [df_pair, 0, 0]\n",
    "        return df_temp\n",
    "    else:\n",
    "        df[\"Previous\"] = (df[\"Distance\"].shift(1))\n",
    "\n",
    "        enter_eval = \"Distance <= \" + str(dist_cutoff) + \" and not (Previous <= \" + str(dist_cutoff) + \")\"\n",
    "        exit_eval = \"Previous <= \" + str(dist_cutoff) + \" and not (Distance <= \" + str(dist_cutoff) + \")\"\n",
    "        df[\"Enter\"] = df.eval(enter_eval).cumsum()\n",
    "        df[\"Exit\"] = df.eval(exit_eval).shift(-1).fillna(True).cumsum()\n",
    "\n",
    "        df_temp = df.merge(df.drop_duplicates(\"Exit\", keep = \"first\")[[\"Timestamp\", \"Exit\"]],\n",
    "                              left_on = \"Enter\", right_on = \"Exit\", how = \"left\", suffixes = [\"\", \"_end\"])\n",
    "\n",
    "        df_temp = df_temp.drop_duplicates(subset = \"Enter\", keep = \"first\")[[\"Pair\", \"Timestamp\", \"Timestamp_end\"]]\n",
    "        if ((df.loc[df[\"Distance\"][0]]) < dist_cutoff) == True:\n",
    "            return df_temp\n",
    "        else:\n",
    "            df_temp = df_temp.loc[1:]\n",
    "            return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee971ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shrimp_df_AC = pd.read_csv('/Users/lukefields/Desktop/Shrimp-Capstone/test_data_out/AC_zebra_distances.csv')\n",
    "shrimp_df_AC = shrimp_df_AC.drop([\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b43f180d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Timestamp_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('A', 'B')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('A', 'C')</td>\n",
       "      <td>0:03:50:61</td>\n",
       "      <td>0:03:50:61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('A', 'D')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('A', 'E')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('B', 'C')</td>\n",
       "      <td>0:01:43: 8</td>\n",
       "      <td>0:01:43: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('B', 'C')</td>\n",
       "      <td>0:02:00:25</td>\n",
       "      <td>0:02:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('B', 'D')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('B', 'E')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('C', 'D')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('C', 'E')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('D', 'E')</td>\n",
       "      <td>0:01:59:28</td>\n",
       "      <td>0:01:59:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pair   Timestamp Timestamp_end\n",
       "10  ('A', 'B')           0             0\n",
       "9   ('A', 'C')  0:03:50:61    0:03:50:61\n",
       "7   ('A', 'D')           0             0\n",
       "8   ('A', 'E')           0             0\n",
       "2   ('B', 'C')  0:01:43: 8    0:01:43: 8\n",
       "3   ('B', 'C')  0:02:00:25    0:02:00:25\n",
       "5   ('B', 'D')           0             0\n",
       "4   ('B', 'E')           0             0\n",
       "1   ('C', 'D')           0             0\n",
       "0   ('C', 'E')           0             0\n",
       "6   ('D', 'E')  0:01:59:28    0:01:59:28"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timestamp_dfs(filepath):\n",
    "    all_files = glob.glob(os.path.join(filepath, \"*.csv\"))\n",
    "\n",
    "    df_storage = []\n",
    "    for filepath in all_files:\n",
    "        individual_df = pd.read_csv(filepath, index_col = None, header = 0)\n",
    "        timestamped_df = important_timestamps(individual_df, 10)\n",
    "        df_storage.append(timestamped_df)\n",
    "\n",
    "    combined_df = pd.concat(df_storage, axis = 0, ignore_index = True)\n",
    "    combined_df = combined_df.sort_values(\"Pair\", ascending = True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "test_path = \"/Users/lukefields/Desktop/Shrimp-Capstone/test_data_out/\"\n",
    "zebra_ts = timestamp_dfs(test_path)\n",
    "zebra_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cfa66a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrimp_df_AC[\"Distance\"][0] < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91fef508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Timestamp_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13834</th>\n",
       "      <td>('A', 'C')</td>\n",
       "      <td>0:03:50:61</td>\n",
       "      <td>0:03:50:61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pair   Timestamp Timestamp_end\n",
       "13834  ('A', 'C')  0:03:50:61    0:03:50:61"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def important_timestamps(df, dist_cutoff):\n",
    "    if ((df.loc[df[\"Distance\"] < dist_cutoff]).empty == True):\n",
    "        df_temp = pd.DataFrame(columns = [\"Pair\", \"Timestamp\", \"Timestamp_end\"],\n",
    "                              index = [0])\n",
    "        df_pair = df[\"Pair\"][0]\n",
    "        df_temp.loc[0] = [df_pair, 0, 0]\n",
    "        return df_temp\n",
    "    else:\n",
    "        df[\"Previous\"] = (df[\"Distance\"].shift(1))\n",
    "\n",
    "        enter_eval = \"Distance <= \" + str(dist_cutoff) + \" and not (Previous <= \" + str(dist_cutoff) + \")\"\n",
    "        exit_eval = \"Previous <= \" + str(dist_cutoff) + \" and not (Distance <= \" + str(dist_cutoff) + \")\"\n",
    "        df[\"Enter\"] = df.eval(enter_eval).cumsum()\n",
    "        df[\"Exit\"] = df.eval(exit_eval).shift(-1).fillna(True).cumsum()\n",
    "\n",
    "        df_temp = df.merge(df.drop_duplicates(\"Exit\", keep = \"first\")[[\"Timestamp\", \"Exit\"]],\n",
    "                              left_on = \"Enter\", right_on = \"Exit\", how = \"left\", suffixes = [\"\", \"_end\"])\n",
    "\n",
    "        df_temp = df_temp.drop_duplicates(subset = \"Enter\", keep = \"first\")[[\"Pair\", \"Timestamp\", \"Timestamp_end\"]]\n",
    "        if df[\"Distance\"][0] < dist_cutoff == True:\n",
    "            return df_temp\n",
    "        else:\n",
    "            df_temp = df_temp.loc[1:]\n",
    "            return df_temp\n",
    "\n",
    "\n",
    "important_timestamps(shrimp_df_AC, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de9016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
